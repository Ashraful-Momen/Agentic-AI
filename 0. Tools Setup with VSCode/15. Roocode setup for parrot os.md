
---

# 1. Your Hardware Summary

* **CPU:** Intel Core i5-6500 (4 cores, 4 threads, no hyperthreading)
* **RAM:** 16 GB
* **GPU:** Intel HD 530 (no CUDA – cannot accelerate embeddings)
* **Storage:** likely SATA/NVME SSD
* **OS:** Parrot Security (Debian-based)

This means:

### Strengths:

* Good single-core performance
* Fast enough SSD
* Can run local embedding models
* Can run Docker + services

### Weaknesses:

* **No GPU → embedding speed is limited**
* **Only 4 CPU cores → cannot run too many parallel tasks**
* **16 GB RAM → need strict memory limits to avoid swapping**

So we must optimize **CPU usage + RAM usage + embedding batching**.

---

# 2. OPTIMAL OLLAMA CONFIG FOR i5-6500 (NO GPU)

Create or edit:

```
~/.ollama/config.yaml
```

Use the **safe and optimal** settings:

```
num_parallel: 2
num_thread: 4
gpu_layers: 0           # because no CUDA
lazy_loading: true
```

Explanation:

* i5-6500 = 4 threads → best batch = 2
* Larger values = system lag + memory pressure

### Embedding batch size for your CPU

Add environment variable:

```
export OLLAMA_EMBED_BATCH=32
```

Reason: CPU cannot handle large batch sizes (like 256).

---

# 3. OPTIMAL QDRANT DOCKER CONFIG (LOW-MEMORY)

Modify your docker-compose:

```
services:
  qdrant:
    image: qdrant/qdrant
    ports:
      - "6333:6333"
    environment:
      QDRANT__STORAGE__ON_DISK: "true"
      QDRANT__STORAGE__WAL: "on"
      QDRANT__STORAGE__WAL_SEGMENT_SIZE_MB: 64
      QDRANT__SERVICE__GRPC_ENABLE: "false"
      QDRANT__TELEMETRY: "false"
      QDRANT__CLUSTER__ENABLED: "false"
      QDRANT__SEARCH__HNSW_ON_DISK: "true"
      QDRANT__SEARCH__MAX_SEARCH_THREADS: 2
    mem_limit: 3g
    cpus: 2.0
```

### Why?

* Limit Qdrant RAM to **3 GB** (your system has 16GB but many services run together).
* Limit CPU to **2 cores** (leaving 2 cores for RooCode + system).
* Enable on-disk HNSW to reduce memory usage.

---

# 4. ROOCODE SETTINGS FOR YOUR MACHINE (VERY IMPORTANT)

Open VS Code → Settings → search “RooCode”.

### Set these:

```
RooCode: Max Files → 20000
RooCode: Threads → 2
RooCode: Embedding Provider → Custom
RooCode: Embedding Model → nomic-embed-text
RooCode: Embedding Batch Size → 32
```

Your current hardware **cannot index 50k+ files at once**.
Instead, use **service-by-service indexing**.

### Exclude heavy folders:

```
**/node_modules/**
**/.next/**
**/vendor/**
**/storage/**
**/dist/**
**/.git/**
```

### Enable cache:

```
RooCode: Use Persistent Cache → true
RooCode: Local Cache Size → 2048 MB
```

---

# 5. VS CODE PERFORMANCE TUNING (CRITICAL FOR LOW-CPU SYSTEM)

Add this to `settings.json`:

```
"files.watcherExclude": {
  "**/node_modules/**": true,
  "**/vendor/**": true,
  "**/.next/**": true,
  "**/dist/**": true
},
"git.autorefresh": false,
"git.enableSmartCommit": false,
"search.followSymlinks": false,
"editor.minimap.enabled": false,
"editor.smoothScrolling": false,
"workbench.tree.indent": 10
```

This reduces the CPU load by ~30%.

---

# 6. OPTIMAL WORKFLOW FOR INDEXING ON YOUR SYSTEM

### Step 1 → index ONE microservice at a time

Example structure:

```
/backend-laravel/
 /admin-panel/
 /ai-service/
 /gateway/
 /frontend-nextjs/
```

Index each separately:

```
cd backend-laravel
```

Let RooCode index.
Then switch workspace to next service.

### This is REQUIRED because your hardware cannot process 50k–200k file repositories at once.

---

# 7. WHICH MODELS TO USE

Because you have no GPU:

### Embeddings:

* **nomic-embed-text (local) – OK**
* Do NOT use:

  * nomic-embed-v1.5-large
  * e5-large
  * bge-large

These will overload your CPU.

### LLM (inside RooCode):

Use your APIs:

* Minimax M2 API
* Z.ai (glm 4.6)

Do NOT use any local LLM for large tokens.
Your CPU cannot handle them.

---

# 8. DO NOT DO THESE (or it will lag/freeze)

* Do NOT run embedding batch above 64
* Do NOT set more than 2 concurrent threads
* Do NOT let Qdrant use more than 3 GB RAM
* Do NOT try to index entire microservice monorepo at once
* Do NOT use GPU-layer settings (you have no CUDA)
* Do NOT run heavy VS Code extensions (SonarLint, GitLens, etc.)

---

# 9. Summary: Best Setup for Your Current Hardware

### Ollama:

* `num_parallel = 2`
* `num_thread = 4`
* `gpu_layers = 0`
* `batch = 32`

### Qdrant:

* RAM limit = 3 GB
* CPU limit = 2 cores
* on-disk HNSW enabled
* WAL enabled

### RooCode:

* index per microservice
* thread count = 2
* max files = 20k
* batch = 32
* persistent cache = 2 GB

### VS Code:

* disable watchers
* disable GitLens / heavy extensions
* disable minimap

---

If you want, I can also provide:

1. A **fully optimized docker-compose.yml** for
   Qdrant + PostgreSQL + Redis + Nginx + Ollama.
2. A complete **settings.json** for RooCode optimized for your system.
3. A benchmark script to test embedding speed and fix bottlenecks.

Which one do you want?
